Day #7 - ğ—–ğ—”ğ—£ ğ—§ğ—µğ—²ğ—¼ğ—¿ğ—²ğ—º(ğ—§ğ—µğ—² ğ—¯ğ—®ğ—°ğ—¸ğ—¯ğ—¼ğ—»ğ—² ğ—¼ğ—³ ğ—®ğ—»ğ˜† ğ—±ğ—¶ğ˜€ğ˜ğ—¿ğ—¶ğ—¯ğ˜‚ğ˜ğ—²ğ—± ğ˜€ğ˜†ğ˜€ğ˜ğ—²ğ—º) - ğ—£ğ—®ğ—¿ğ˜(2):

Its already a week!!!

Lets go through 5 examples to make sure we will always correctly prioritize the system:
ğ—•ğ—®ğ—»ğ—¸ğ—¶ğ—»ğ—´ ğ—¦ğ˜†ğ˜€ğ˜ğ—²ğ—º ğ—–ğ—£
-> Atomic level transaction is very important to be consistent throughout.
ğ—˜-ğ—°ğ—¼ğ—ºğ—ºğ—²ğ—¿ğ—°ğ—² ğ—ªğ—²ğ—¯ğ˜€ğ—¶ğ˜ğ—² (ğ—™ğ—¹ğ—®ğ˜€ğ—µ ğ—¦ğ—®ğ—¹ğ—²) ğ—”ğ—£
-> Data availability is very important.
ğ—¦ğ—¼ğ—°ğ—¶ğ—®ğ—¹ ğ— ğ—²ğ—±ğ—¶ğ—® ğ—™ğ—²ğ—²ğ—± ğ—”ğ—£
-> Data should be available at all times.
ğ—¦ğ˜ğ—¼ğ—°ğ—¸ ğ—§ğ—¿ğ—®ğ—±ğ—¶ğ—»ğ—´ ğ—£ğ—¹ğ—®ğ˜ğ—³ğ—¼ğ—¿ğ—º ğ—–ğ—£
-> Atomic level transaction is very important to be consistent throughout.
ğ—–ğ—¼ğ—»ğ˜ğ—²ğ—»ğ˜ ğ——ğ—²ğ—¹ğ—¶ğ˜ƒğ—²ğ—¿ğ˜† ğ—¡ğ—²ğ˜ğ˜„ğ—¼ğ—¿ğ—¸ (ğ—–ğ——ğ—¡) ğ—”ğ—£
-> Video steaming service use this, explained on day 6
ğ—›ğ—²ğ—®ğ—¹ğ˜ğ—µğ—°ğ—®ğ—¿ğ—² ğ—¦ğ˜†ğ˜€ğ˜ğ—²ğ—º ğ—–ğ—£
-> Data consistency hold priority.

Always remember distributed system will always have Partition tolerance, so our task becomes very easy.

Implementations:

ğ—–ğ—¼ğ—»ğ˜€ğ—¶ğ˜€ğ˜ğ—²ğ—»ğ—°ğ˜†:: 
-> ğ‘ºğ’šğ’ğ’„ğ’‰ğ’“ğ’ğ’ğ’ğ’–ğ’” ğ’„ğ’‚ğ’ğ’ğ’” - All nodes must be successfully updated for the transaction to commit, else rollback occurs and call fails.
-> 2ğ‘·ğ‘ª(2-ğ’‘ğ’‰ğ’‚ğ’”ğ’† ğ’‘ğ’“ğ’ğ’•ğ’ğ’„ğ’ğ’) - 2 phases occurs, "prepare" phase, where all nodes are available to commit, thus ensuring full transaction and "commit" phase, where we get the confirmation of write.

There are some others as well, Need to research and learn more about them (Strong Quorum-based, Locks and Paxos/Raft Consensus).

ğ—”ğ˜ƒğ—®ğ—¶ğ—¹ğ—®ğ—¯ğ—¶ğ—¹ğ—¶ğ˜ğ˜†:: 
-> ğ’‚ğ’”ğ’šğ’ğ’„ğ’‰ğ’“ğ’ğ’ğ’ğ’–ğ’” ğ’„ğ’‚ğ’ğ’ğ’” - notify the user of successful write for the current data node, for the rest, an asynchronous call goes to do the write via some event.
-> ğ‘ºğ’‰ğ’‚ğ’“ğ’…ğ’Šğ’ğ’ˆ ğ’‚ğ’ğ’… ğ’“ğ’†ğ’‘ğ’ğ’Šğ’„ğ’‚ğ’•ğ’Šğ’ğ’- Sharding means breaking the database into chunks and putting them on different nodes and replication is creating same database on another node. We can achieve high availability by combining the 2.

ğ—£ğ—®ğ—¿ğ˜ğ—¶ğ˜ğ—¶ğ—¼ğ—» ğ˜ğ—¼ğ—¹ğ—²ğ—¿ğ—®ğ—»ğ—°ğ—²::
-> ğ‘¹ğ’†ğ’‘ğ’ğ’Šğ’„ğ’‚ğ’•ğ’Šğ’ğ’ - replicating the database, even if 1 node fails, we have a copy.
-> ğ‘­ğ’‚ğ’–ğ’ğ’• ğ’•ğ’ğ’ğ’†ğ’“ğ’‚ğ’ğ’„ğ’† - use routing algorithms and retry mechanism to route read and write to the replicated nodes which are non faulty.

Taking part in a hackathon for the weekend, Will share some learning from there, If I can.

Godspeed! âœŒ